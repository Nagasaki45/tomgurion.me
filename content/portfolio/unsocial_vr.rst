Unsocial VR
###########

:date: 2017-07-14 10:00
:order: 02
:img: unsocial-vr.png
:windowed_img: unsocial-vr-window.png
:summary: Fake social behaviours in shared virtual environment
:links: source code;https://github.com/Nagasaki45/UnsocialVR;fa-github

Advance Project Placement, Media and Arts Technology doctoral programme, Queen Mary University of London.
Supervised by Prof. Patrick Healey and hosted by `Inition <https://www.inition.co.uk/>`_.

.. youtube:: tqbtOL5R4fw

What?
-----

In Infinite Jest, David Foster Wallace argues that *"Good old traditional audio-only phone conversations allowed you to presume that the person on the other end was paying complete attention to you while also permitting you not to have to pay anything even close to complete attention to her."*
He continues and claims that we are addicted to this illusion, and that's why video conferencing always feel so awkward - we need to pretend to listen all the time.
And if we think about it, even in face to face conversation we must always adhere to these social rules, and signal our complete attention when someone is talking to us.

In this project I experiment with VR technologies to see if this illusion of faking active listening is transferable to other mediums, and if so, how.
In Unsocial VR participants share the same virtual environment, using the HTC Vive headset and controllers.
They can converse freely and move around, and if you want to start faking listening to the conversation and just wander around, or even talk with other participants while faking, you absolutely can!
The interface is very minimal, just hit a button on the controller to start faking active listening behaviours towards your current conversation, and release it when you want to stop faking.
You will even get an on screen notification when someone is speaking directly to you, so you can return to the conversation elegantly.

This project is based on multidisciplinary research.
It merges ideas from telepresence and mediated communication, that explore ways to represent non verbal cues in new communication technologies.
It depends on multiparty social interaction analysis, which take spatial cues into account in understanding who is talking with whom in a "cocktail party" situation.
It explores new ways to generate active listening signals (or "backchannel behaviours", as they called in the scientific literature), such as head nods, in automated agents.

Further information can be found in my `mid-project <https://youtu.be/K39_wlQ60-Y>`_ and `inter/sections <https://youtu.be/2k8MO74guTA>`_ presentations.
